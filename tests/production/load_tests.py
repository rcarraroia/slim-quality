#!/usr/bin/env python3
"""
Testes de carga para produ√ß√£o - Stress testing
"""
import asyncio
import json
import time
import statistics
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional

import httpx
import structlog

logger = structlog.get_logger(__name__)


class LoadTestRunner:
    """Runner para testes de carga em produ√ß√£o."""
    
    def __init__(self, base_url: str = "https://api.slimquality.com.br"):
        self.base_url = base_url
        self.results = []
        self.start_time = time.time()
    
    async def single_request(self, session: httpx.AsyncClient, endpoint: str) -> Dict[str, Any]:
        """Executa uma √∫nica requisi√ß√£o."""
        start_time = time.time()
        
        try:
            response = await session.get(f"{self.base_url}{endpoint}")
            duration = (time.time() - start_time) * 1000
            
            return {
                "success": True,
                "status_code": response.status_code,
                "duration_ms": duration,
                "response_size": len(response.content)
            }
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            return {
                "success": False,
                "status_code": 0,
                "duration_ms": duration,
                "error": str(e)
            }
    
    async def load_test_endpoint(self, endpoint: str, concurrent_users: int, 
                               requests_per_user: int, description: str) -> Dict[str, Any]:
        """
        Executa teste de carga em um endpoint espec√≠fico.
        
        Args:
            endpoint: Endpoint a ser testado
            concurrent_users: N√∫mero de usu√°rios simult√¢neos
            requests_per_user: Requisi√ß√µes por usu√°rio
            description: Descri√ß√£o do teste
        """
        test_start = time.time()
        
        logger.info(f"üöÄ Iniciando teste de carga: {description}")
        logger.info(f"   Endpoint: {endpoint}")
        logger.info(f"   Usu√°rios simult√¢neos: {concurrent_users}")
        logger.info(f"   Requisi√ß√µes por usu√°rio: {requests_per_user}")
        
        total_requests = concurrent_users * requests_per_user
        all_results = []
        
        try:
            # Criar sess√µes HTTP para cada usu√°rio
            async with httpx.AsyncClient(
                timeout=httpx.Timeout(30.0),
                limits=httpx.Limits(max_connections=concurrent_users * 2)
            ) as client:
                
                async def user_session():
                    """Simula um usu√°rio fazendo m√∫ltiplas requisi√ß√µes."""
                    user_results = []
                    for _ in range(requests_per_user):
                        result = await self.single_request(client, endpoint)
                        user_results.append(result)
                        # Pequeno delay entre requisi√ß√µes do mesmo usu√°rio
                        await asyncio.sleep(0.1)
                    return user_results
                
                # Executar todos os usu√°rios simultaneamente
                user_tasks = [user_session() for _ in range(concurrent_users)]
                user_results_list = await asyncio.gather(*user_tasks)
                
                # Flatten results
                for user_results in user_results_list:
                    all_results.extend(user_results)
            
            # Calcular estat√≠sticas
            successful_requests = [r for r in all_results if r["success"]]
            failed_requests = [r for r in all_results if not r["success"]]
            
            success_count = len(successful_requests)
            failure_count = len(failed_requests)
            success_rate = (success_count / total_requests) * 100 if total_requests > 0 else 0
            
            # Estat√≠sticas de tempo de resposta
            response_times = [r["duration_ms"] for r in successful_requests]
            
            if response_times:
                avg_response = statistics.mean(response_times)
                median_response = statistics.median(response_times)
                p95_response = statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else max(response_times)
                p99_response = statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else max(response_times)
                min_response = min(response_times)
                max_response = max(response_times)
            else:
                avg_response = median_response = p95_response = p99_response = min_response = max_response = 0
            
            # Throughput (requisi√ß√µes por segundo)
            total_duration = time.time() - test_start
            throughput = total_requests / total_duration if total_duration > 0 else 0
            
            # Status codes
            status_codes = {}
            for result in all_results:
                code = result.get("status_code", 0)
                status_codes[code] = status_codes.get(code, 0) + 1
            
            # Avaliar se o teste passou
            test_passed = (
                success_rate >= 95 and  # 95% de sucesso
                avg_response < 2000 and  # M√©dia < 2s
                p95_response < 5000  # P95 < 5s
            )
            
            result = {
                "test": description,
                "endpoint": endpoint,
                "success": test_passed,
                "duration_seconds": round(total_duration, 2),
                "concurrent_users": concurrent_users,
                "requests_per_user": requests_per_user,
                "total_requests": total_requests,
                "successful_requests": success_count,
                "failed_requests": failure_count,
                "success_rate": round(success_rate, 2),
                "throughput_rps": round(throughput, 2),
                "response_times": {
                    "avg_ms": round(avg_response, 2),
                    "median_ms": round(median_response, 2),
                    "p95_ms": round(p95_response, 2),
                    "p99_ms": round(p99_response, 2),
                    "min_ms": round(min_response, 2),
                    "max_ms": round(max_response, 2)
                },
                "status_codes": status_codes,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            if test_passed:
                logger.info(f"‚úÖ {description} - {success_rate:.1f}% sucesso, {avg_response:.0f}ms m√©dio, {throughput:.1f} RPS")
            else:
                logger.warning(f"‚ö†Ô∏è {description} - {success_rate:.1f}% sucesso, {avg_response:.0f}ms m√©dio, {throughput:.1f} RPS")
            
            self.results.append(result)
            return result
            
        except Exception as e:
            total_duration = time.time() - test_start
            
            result = {
                "test": description,
                "endpoint": endpoint,
                "success": False,
                "duration_seconds": round(total_duration, 2),
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            logger.error(f"‚ùå Exce√ß√£o no teste de carga {description}: {e}")
            self.results.append(result)
            return result
    
    async def memory_leak_test(self) -> Dict[str, Any]:
        """Testa vazamentos de mem√≥ria com requisi√ß√µes prolongadas."""
        test_start = time.time()
        
        logger.info("üß† Iniciando teste de vazamento de mem√≥ria...")
        
        try:
            # Fazer muitas requisi√ß√µes sequenciais para detectar vazamentos
            num_requests = 100
            results = []
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                for i in range(num_requests):
                    result = await self.single_request(client, "/health")
                    results.append(result)
                    
                    # Log progresso a cada 25 requisi√ß√µes
                    if (i + 1) % 25 == 0:
                        logger.info(f"   Progresso: {i + 1}/{num_requests} requisi√ß√µes")
                    
                    # Pequeno delay
                    await asyncio.sleep(0.05)
            
            # Analisar tend√™ncias de tempo de resposta
            successful_results = [r for r in results if r["success"]]
            response_times = [r["duration_ms"] for r in successful_results]
            
            if len(response_times) >= 50:
                # Comparar primeira metade com segunda metade
                first_half = response_times[:len(response_times)//2]
                second_half = response_times[len(response_times)//2:]
                
                avg_first = statistics.mean(first_half)
                avg_second = statistics.mean(second_half)
                
                # Se segunda metade √© significativamente mais lenta, pode indicar vazamento
                degradation_percent = ((avg_second - avg_first) / avg_first) * 100 if avg_first > 0 else 0
                
                # Considerar problem√°tico se degrada√ß√£o > 50%
                memory_leak_detected = degradation_percent > 50
            else:
                avg_first = avg_second = degradation_percent = 0
                memory_leak_detected = False
            
            success_rate = (len(successful_results) / num_requests) * 100
            total_duration = time.time() - test_start
            
            result = {
                "test": "Teste de Vazamento de Mem√≥ria",
                "success": not memory_leak_detected and success_rate >= 95,
                "duration_seconds": round(total_duration, 2),
                "total_requests": num_requests,
                "successful_requests": len(successful_results),
                "success_rate": round(success_rate, 2),
                "avg_response_first_half_ms": round(avg_first, 2),
                "avg_response_second_half_ms": round(avg_second, 2),
                "performance_degradation_percent": round(degradation_percent, 2),
                "memory_leak_detected": memory_leak_detected,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            if result["success"]:
                logger.info(f"‚úÖ Teste de mem√≥ria OK - {degradation_percent:.1f}% degrada√ß√£o")
            else:
                logger.warning(f"‚ö†Ô∏è Poss√≠vel vazamento de mem√≥ria - {degradation_percent:.1f}% degrada√ß√£o")
            
            self.results.append(result)
            return result
            
        except Exception as e:
            total_duration = time.time() - test_start
            
            result = {
                "test": "Teste de Vazamento de Mem√≥ria",
                "success": False,
                "duration_seconds": round(total_duration, 2),
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            logger.error(f"‚ùå Exce√ß√£o no teste de mem√≥ria: {e}")
            self.results.append(result)
            return result
    
    async def run_all_load_tests(self) -> Dict[str, Any]:
        """Executa todos os testes de carga."""
        logger.info("‚ö° Iniciando testes de carga de produ√ß√£o...")
        
        # Testes de carga progressivos
        tests = [
            # Teste leve
            self.load_test_endpoint(
                "/health", 5, 10, 
                "Teste Leve - 5 usu√°rios, 10 req/usu√°rio"
            ),
            
            # Teste moderado
            self.load_test_endpoint(
                "/health", 20, 5,
                "Teste Moderado - 20 usu√°rios, 5 req/usu√°rio"
            ),
            
            # Teste de pico
            self.load_test_endpoint(
                "/health", 50, 2,
                "Teste de Pico - 50 usu√°rios, 2 req/usu√°rio"
            ),
            
            # Teste de webhook
            self.load_test_endpoint(
                "/webhooks/metrics", 10, 5,
                "Teste Webhook Metrics - 10 usu√°rios, 5 req/usu√°rio"
            ),
            
            # Teste de vazamento de mem√≥ria
            self.memory_leak_test()
        ]
        
        # Executar testes sequencialmente (n√£o simult√¢neos para n√£o sobrecarregar)
        for test in tests:
            await test
            # Pausa entre testes para recupera√ß√£o
            await asyncio.sleep(2)
        
        # Calcular estat√≠sticas gerais
        total_tests = len(self.results)
        successful_tests = len([r for r in self.results if r.get("success", False)])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        total_duration = time.time() - self.start_time
        
        summary = {
            "load_tests_summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "failed_tests": failed_tests,
                "success_rate": round(success_rate, 1),
                "total_duration_seconds": round(total_duration, 2),
                "timestamp": datetime.now(timezone.utc).isoformat()
            },
            "test_results": self.results
        }
        
        # Log do resumo
        if success_rate >= 80:
            logger.info(
                f"‚úÖ Testes de carga conclu√≠dos - {success_rate:.1f}% sucesso ({successful_tests}/{total_tests})"
            )
        else:
            logger.error(
                f"‚ùå Testes de carga falharam - {success_rate:.1f}% sucesso ({successful_tests}/{total_tests})"
            )
        
        return summary


async def main():
    """Fun√ß√£o principal para executar testes de carga."""
    import sys
    
    # URL base (pode ser passada como argumento)
    base_url = sys.argv[1] if len(sys.argv) > 1 else "https://api.slimquality.com.br"
    
    print(f"‚ö° Executando testes de carga em: {base_url}")
    print("=" * 50)
    print("‚ö†Ô∏è  ATEN√á√ÉO: Testes de carga podem impactar o sistema temporariamente")
    print("")
    
    runner = LoadTestRunner(base_url)
    summary = await runner.run_all_load_tests()
    
    # Imprimir resumo
    print("\nüìä RESUMO DOS TESTES DE CARGA")
    print("=" * 35)
    
    stats = summary["load_tests_summary"]
    print(f"Total de testes: {stats['total_tests']}")
    print(f"Sucessos: {stats['successful_tests']}")
    print(f"Falhas: {stats['failed_tests']}")
    print(f"Taxa de sucesso: {stats['success_rate']}%")
    print(f"Dura√ß√£o total: {stats['total_duration_seconds']}s")
    
    # Salvar resultados
    with open("load_tests_results.json", "w") as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nüìÑ Resultados salvos em: load_tests_results.json")
    
    # Exit code baseado no sucesso
    if stats["success_rate"] >= 80:
        print("‚úÖ Testes de carga PASSARAM!")
        sys.exit(0)
    else:
        print("‚ùå Testes de carga FALHARAM!")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())