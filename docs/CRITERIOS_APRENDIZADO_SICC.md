# üìä CRIT√âRIOS DE APRENDIZADO DO SICC - AN√ÅLISE COMPLETA

**Sistema de Intelig√™ncia Corporativa Cont√≠nua - Slim Quality**

---

## üéØ VIS√ÉO GERAL

O Sistema SICC (Sistema de Intelig√™ncia Corporativa Cont√≠nua) √© respons√°vel por identificar padr√µes comportamentais em conversas e gerar aprendizados automaticamente. Este documento detalha **exatamente quando uma conversa se torna um novo aprendizado** no sistema.

### **Objetivo do SICC:**
- Analisar conversas em tempo real
- Identificar padr√µes recorrentes de comportamento
- Gerar aprendizados autom√°ticos para melhorar respostas
- Aplicar conhecimento adquirido em futuras intera√ß√µes

---

## üîß CONFIGURA√á√ïES PRINCIPAIS

### **Par√¢metros Cr√≠ticos do Sistema:**

```python
# Configura√ß√µes do LearningService
self.min_pattern_frequency = 3          # M√≠nimo de ocorr√™ncias para considerar padr√£o
self.min_confidence_threshold = 0.7     # M√≠nimo de confian√ßa para aprova√ß√£o autom√°tica  
self.analysis_window_days = 30          # Janela de an√°lise em dias
self.max_patterns_per_analysis = 50     # M√°ximo de padr√µes por an√°lise
```

### **Par√¢metros do SupervisorService:**

```python
# Configura√ß√µes de aprova√ß√£o autom√°tica
self.default_threshold = 0.7            # Threshold padr√£o de aprova√ß√£o
self.conflict_severity_threshold = 0.2  # Limite de severidade de conflitos
```

---

## üìã CRIT√âRIOS OBRIGAT√ìRIOS PARA APRENDIZADO

Para que uma conversa se torne um aprendizado, **TODOS** os crit√©rios abaixo devem ser atendidos:

### **1. üî¢ FREQU√äNCIA M√çNIMA**
- **Requisito:** M√≠nimo **3 ocorr√™ncias** do mesmo padr√£o
- **L√≥gica:** `len(type_memories) >= self.min_pattern_frequency`
- **Exemplo:** Uma resposta sobre "dores nas costas" precisa aparecer pelo menos 3 vezes

### **2. üìä CONFIDENCE SCORE**
- **Requisito:** M√≠nimo **70% de confian√ßa**
- **C√°lculo:** `confidence = min(0.9, len(type_memories) / 10.0)`
- **Exemplo:** 7 ocorr√™ncias = 70% confidence (aprovado)

### **3. ‚è∞ JANELA TEMPORAL**
- **Requisito:** Padr√µes dos **√∫ltimos 30 dias**
- **L√≥gica:** `cutoff_date = datetime.utcnow() - timedelta(days=30)`
- **Motivo:** Focar em comportamentos recentes e relevantes

### **4. üéØ CONSIST√äNCIA**
- **Requisito:** Respostas similares entre si
- **M√©todo:** An√°lise de palavras-chave e frases comuns
- **Valida√ß√£o:** Similaridade Jaccard entre conte√∫dos

### **5. ‚öñÔ∏è AUS√äNCIA DE CONFLITOS**
- **Requisito:** N√£o conflitar com padr√µes existentes
- **Limite:** Similaridade < 70% com triggers existentes
- **Valida√ß√£o:** SupervisorService.validate_pattern_conflicts()

### **6. ‚úÖ APROVA√á√ÉO AUTOM√ÅTICA**
- **Requisito:** Passar pela valida√ß√£o do SupervisorService
- **M√©todo:** `auto_approve(confidence_score, threshold)`
- **Resultado:** `confidence_score >= threshold`

---

## üîç PROCESSO DETALHADO DE AN√ÅLISE

### **ETAPA 1: Coleta de Mem√≥rias**
```python
# Buscar mem√≥rias da conversa nos √∫ltimos X dias
memories = await self._get_conversation_memories(conversation_id, limit_days)

# Valida√ß√£o m√≠nima
if len(memories) < self.min_pattern_frequency:
    return []  # N√£o h√° mem√≥rias suficientes
```

### **ETAPA 2: Categoriza√ß√£o de Respostas**
O sistema identifica tipos de resposta:

| Tipo | Palavras-chave | Exemplo |
|------|----------------|---------|
| `question_response` | pergunta, quest√£o, d√∫vida | "Sobre sua d√∫vida..." |
| `explanation` | explica√ß√£o, explicar, como | "Vou explicar como funciona..." |
| `problem_solving` | problema, erro, falha | "Para resolver esse problema..." |
| `suggestion` | sugest√£o, recomenda√ß√£o, sugiro | "Sugiro que voc√™..." |
| `confirmation` | confirma√ß√£o, confirmar, ok | "Confirmado, pode prosseguir..." |
| `general_response` | Outros casos | Resposta geral |

### **ETAPA 3: C√°lculo de Confidence**
```python
# Para cada tipo de resposta com frequ√™ncia suficiente
for response_type, type_memories in response_types.items():
    if len(type_memories) >= self.min_pattern_frequency:
        # Calcular confian√ßa baseada na frequ√™ncia
        confidence = min(0.9, len(type_memories) / 10.0)
        
        # Criar padr√£o se confidence suficiente
        if confidence >= 0.3:  # Filtro m√≠nimo
            pattern = Pattern(...)
```

### **ETAPA 4: Valida√ß√£o de Conflitos**
```python
# Verificar similaridade com padr√µes existentes
for existing in existing_patterns:
    similarity = self._calculate_similarity(new_trigger, existing_trigger)
    
    if similarity > 0.7:  # Conflito detectado
        conflict = ConflictDetail(
            type="trigger_similarity",
            severity=similarity,
            description="Trigger similar ao padr√£o existente"
        )
```

### **ETAPA 5: Aprova√ß√£o Final**
```python
# SupervisorService decide aprova√ß√£o
should_approve = await supervisor_service.auto_approve(
    confidence_score=pattern.confidence,
    threshold=0.7
)

if should_approve:
    # Criar learning_log
    learning_log = LearningLog(
        pattern_id=pattern.id,
        confidence_score=confidence_score,
        status="approved"
    )
```

---

## üìä EXEMPLOS PR√ÅTICOS

### ‚úÖ **CEN√ÅRIO QUE VIRA APRENDIZADO**

**Situa√ß√£o:** Cliente pergunta sobre dores nas costas

**Dados coletados:**
- **Ocorr√™ncias:** 8 vezes nos √∫ltimos 20 dias
- **Confidence calculado:** 80% (8 √∑ 10)
- **Similaridade:** Respostas consistentes sobre colch√£o magn√©tico
- **Conflitos:** Nenhum padr√£o similar existente

**Resultado:** ‚úÖ **APROVADO AUTOMATICAMENTE**

```json
{
  "pattern_id": "pat_001",
  "pattern_type": "problem_solving",
  "trigger": "Cliente menciona dores nas costas",
  "action": "Recomendar colch√£o magn√©tico com foco terap√™utico",
  "confidence": 0.8,
  "frequency": 8,
  "status": "approved"
}
```

### ‚ùå **CEN√ÅRIO QUE N√ÉO VIRA APRENDIZADO**

**Situa√ß√£o:** Cliente pergunta sobre entrega

**Dados coletados:**
- **Ocorr√™ncias:** 2 vezes nos √∫ltimos 10 dias
- **Confidence calculado:** 20% (2 √∑ 10)
- **Motivo da rejei√ß√£o:** Frequ√™ncia insuficiente (< 3) E confidence baixo (< 70%)

**Resultado:** ‚ùå **REJEITADO AUTOMATICAMENTE**

### ‚ö†Ô∏è **CEN√ÅRIO QUE PRECISA REVIS√ÉO MANUAL**

**Situa√ß√£o:** Cliente pergunta sobre pre√ßos

**Dados coletados:**
- **Ocorr√™ncias:** 6 vezes nos √∫ltimos 15 dias
- **Confidence calculado:** 60% (6 √∑ 10)
- **Conflito detectado:** Similaridade 75% com padr√£o existente sobre "valores"

**Resultado:** ‚ö†Ô∏è **NEEDS_REVIEW** (conflito cr√≠tico)

---

## üóÑÔ∏è ESTRUTURA DO BANCO DE DADOS

### **Tabela: `learning_logs`**
```sql
CREATE TABLE learning_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    pattern_id UUID NOT NULL,
    learning_type VARCHAR(50) NOT NULL,
    description TEXT NOT NULL,
    confidence_score FLOAT NOT NULL CHECK (confidence_score >= 0 AND confidence_score <= 1),
    evidence JSONB NOT NULL DEFAULT '[]',
    proposed_changes JSONB NOT NULL DEFAULT '{}',
    status VARCHAR(20) NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'approved', 'rejected')),
    approval_reason TEXT,
    approved_by VARCHAR(50) DEFAULT 'supervisor_auto',
    approved_at TIMESTAMPTZ NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### **Tabela: `behavior_patterns`**
```sql
CREATE TABLE behavior_patterns (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    pattern_type VARCHAR(50) NOT NULL,
    trigger_condition TEXT NOT NULL,
    action_template TEXT NOT NULL,
    confidence_score FLOAT NOT NULL CHECK (confidence_score >= 0 AND confidence_score <= 1),
    usage_count INTEGER DEFAULT 0,
    success_rate FLOAT DEFAULT 0.0,
    metadata JSONB DEFAULT '{}',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### **Tabela: `memory_chunks`**
```sql
CREATE TABLE memory_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL,
    content TEXT NOT NULL,
    embedding vector(384),
    metadata JSONB DEFAULT '{}',
    relevance_score FLOAT DEFAULT 0.0,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

## üìà QUERIES PARA MONITORAMENTO

### **1. Ver Aprendizados Recentes**
```sql
SELECT 
    id,
    learning_type,
    description,
    confidence_score,
    status,
    approved_by,
    created_at,
    approved_at
FROM learning_logs 
WHERE created_at >= NOW() - INTERVAL '7 days'
ORDER BY created_at DESC;
```

### **2. Padr√µes Mais Utilizados**
```sql
SELECT 
    id,
    pattern_type,
    trigger_condition,
    confidence_score,
    usage_count,
    success_rate,
    created_at
FROM behavior_patterns 
WHERE is_active = true
  AND confidence_score >= 0.7
ORDER BY usage_count DESC
LIMIT 10;
```

### **3. M√©tricas de Performance**
```sql
SELECT 
    metric_type,
    metric_value,
    measurement_date,
    metadata
FROM agent_performance_metrics 
WHERE metric_type IN (
    'patterns_identified_daily',
    'patterns_approved_daily',
    'patterns_rejected_daily',
    'patterns_applied_daily'
)
AND measurement_date >= CURRENT_DATE - INTERVAL '30 days'
ORDER BY measurement_date DESC, metric_type;
```

### **4. An√°lise de Confidence**
```sql
-- Distribui√ß√£o de confidence scores
SELECT 
    CASE 
        WHEN confidence_score >= 0.9 THEN 'Muito Alto (90%+)'
        WHEN confidence_score >= 0.7 THEN 'Alto (70-89%)'
        WHEN confidence_score >= 0.5 THEN 'M√©dio (50-69%)'
        ELSE 'Baixo (<50%)'
    END as confidence_range,
    COUNT(*) as total_patterns,
    AVG(usage_count) as avg_usage
FROM behavior_patterns 
WHERE is_active = true
GROUP BY confidence_range
ORDER BY MIN(confidence_score) DESC;
```

---

## üîß CONFIGURA√á√ïES AVAN√áADAS

### **Ajustar Sensibilidade do Sistema:**

```python
# Para sistema mais conservador (menos aprendizados)
self.min_pattern_frequency = 5      # Aumentar para 5 ocorr√™ncias
self.min_confidence_threshold = 0.8 # Aumentar para 80%

# Para sistema mais liberal (mais aprendizados)
self.min_pattern_frequency = 2      # Diminuir para 2 ocorr√™ncias  
self.min_confidence_threshold = 0.6 # Diminuir para 60%
```

### **Ajustar Janela Temporal:**

```python
# An√°lise mais recente (√∫ltimos 15 dias)
self.analysis_window_days = 15

# An√°lise mais ampla (√∫ltimos 60 dias)
self.analysis_window_days = 60
```

---

## üö® TROUBLESHOOTING

### **Problema: Muitos aprendizados sendo criados**
**Solu√ß√£o:**
- Aumentar `min_pattern_frequency` para 4 ou 5
- Aumentar `min_confidence_threshold` para 0.8
- Diminuir `analysis_window_days` para 15

### **Problema: Poucos aprendizados sendo criados**
**Solu√ß√£o:**
- Diminuir `min_pattern_frequency` para 2
- Diminuir `min_confidence_threshold` para 0.6
- Aumentar `analysis_window_days` para 45

### **Problema: Conflitos frequentes**
**Solu√ß√£o:**
- Diminuir `conflict_severity_threshold` para 0.1
- Revisar padr√µes existentes para remover duplicatas
- Implementar merge autom√°tico de padr√µes similares

---

## üìä M√âTRICAS DE SUCESSO

### **KPIs do Sistema de Aprendizado:**

| M√©trica | Meta | Descri√ß√£o |
|---------|------|-----------|
| **Taxa de Aprova√ß√£o** | 70-80% | % de padr√µes aprovados automaticamente |
| **Confidence M√©dio** | > 0.75 | Confidence m√©dio dos padr√µes aprovados |
| **Tempo de An√°lise** | < 5 min | Tempo para processar uma conversa |
| **Taxa de Conflitos** | < 10% | % de padr√µes com conflitos detectados |
| **Aplica√ß√£o de Padr√µes** | > 60% | % de padr√µes efetivamente utilizados |

### **Monitoramento Cont√≠nuo:**
```sql
-- Dashboard de m√©tricas di√°rias
SELECT 
    DATE(created_at) as data,
    COUNT(*) as total_aprendizados,
    COUNT(*) FILTER (WHERE status = 'approved') as aprovados,
    COUNT(*) FILTER (WHERE status = 'rejected') as rejeitados,
    AVG(confidence_score) as confidence_medio
FROM learning_logs 
WHERE created_at >= NOW() - INTERVAL '30 days'
GROUP BY DATE(created_at)
ORDER BY data DESC;
```

---

## üîÑ FLUXO COMPLETO DE APRENDIZADO

```mermaid
graph TD
    A[Conversa Finalizada] --> B[Coletar Mem√≥rias]
    B --> C{Mem√≥rias >= 3?}
    C -->|N√£o| D[N√£o Gerar Aprendizado]
    C -->|Sim| E[Analisar Padr√µes]
    E --> F[Calcular Confidence]
    F --> G{Confidence >= 70%?}
    G -->|N√£o| D
    G -->|Sim| H[Validar Conflitos]
    H --> I{Conflitos Cr√≠ticos?}
    I -->|Sim| J[Marcar para Revis√£o]
    I -->|N√£o| K[Aprova√ß√£o Autom√°tica]
    K --> L[Salvar Learning Log]
    L --> M[Aplicar Padr√£o]
    J --> N[Aguardar Revis√£o Manual]
```

---

## üìö REFER√äNCIAS T√âCNICAS

### **Arquivos Principais:**
- `agent/src/services/sicc/learning_service.py` - L√≥gica de aprendizado
- `agent/src/services/sicc/supervisor_service.py` - Aprova√ß√£o autom√°tica
- `agent/src/services/sicc/sicc_service.py` - Orquestrador principal
- `agent/src/services/sicc/memory_service.py` - Gest√£o de mem√≥rias

### **Migrations Relacionadas:**
- `20251228174600_create_learning_logs.sql`
- `20251228174500_create_behavior_patterns.sql`
- `20251228174400_create_memory_chunks.sql`

### **Testes de Propriedade:**
- `agent/tests/test_supervisor_properties_simple.py`
- `agent/tests/test_supervisor_conflict_properties.py`

---

## üìû SUPORTE

Para d√∫vidas sobre os crit√©rios de aprendizado:

1. **Consultar logs:** `learning_logs` table no Supabase
2. **Verificar m√©tricas:** `agent_performance_metrics` table
3. **Analisar padr√µes:** `behavior_patterns` table
4. **Revisar mem√≥rias:** `memory_chunks` table

**Documento atualizado em:** Janeiro 2025  
**Vers√£o:** 1.0  
**Autor:** Sistema SICC - Slim Quality