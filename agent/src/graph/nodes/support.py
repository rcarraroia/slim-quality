"""
Support Node - Suporte e atendimento
"""
import structlog
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, AIMessage

from ..state import AgentState
from ...config import get_settings

logger = structlog.get_logger(__name__)


def detect_human_transfer(message_content: str) -> bool:
    """
    Detecta se a mensagem requer transfer√™ncia para humano.
    
    Crit√©rios:
    - Reclama√ß√µes graves
    - Problemas complexos n√£o resolvidos
    - Solicita√ß√£o expl√≠cita de falar com humano
    
    Args:
        message_content: Conte√∫do da mensagem do agente
        
    Returns:
        True se deve transferir, False caso contr√°rio
    """
    transfer_keywords = [
        "transferir para humano",
        "falar com atendente",
        "preciso de ajuda humana",
        "n√£o consigo resolver",
        "problema complexo",
        "reclama√ß√£o grave"
    ]
    
    message_lower = message_content.lower()
    return any(keyword in message_lower for keyword in transfer_keywords)


async def support_node(state: AgentState) -> AgentState:
    """
    Responde d√∫vidas e fornece suporte usando contexto SICC.
    
    Responsabilidades:
    - Responder d√∫vidas sobre garantia, frete, troca, pagamento
    - Fornecer informa√ß√µes sobre pol√≠ticas da empresa
    - Detectar necessidade de transfer√™ncia para humano
    - Usar contexto SICC para personaliza√ß√£o
    - Notificar via MCP quando necess√°rio
    
    Args:
        state: Estado atual da conversa√ß√£o
        
    Returns:
        Estado atualizado com nova mensagem
    """
    logger.info("support_node: Fornecendo suporte com contexto SICC")
    
    # Obter contexto SICC
    sicc_context = state.get("sicc_context", {})
    customer_context = state.get("customer_context", {})
    sicc_patterns = state.get("sicc_patterns", [])
    
    # Obter configura√ß√µes
    settings = get_settings()
    
    # Inicializar Claude
    llm = ChatAnthropic(
        model=settings.claude_model,
        api_key=settings.claude_api_key,
        temperature=0.5  # Temperatura baixa para respostas precisas
    )
    
    # Obter nome do lead se dispon√≠vel
    lead_data = state.get("lead_data", {})
    nome = lead_data.get("nome", "")
    
    # Construir contexto personalizado
    personalization = f"""
CONTEXTO DO CLIENTE:
- Nome: {customer_context.get('customer_name', nome if nome else 'Cliente')}
- Cliente retornando: {customer_context.get('is_returning_customer', False)}
- Hist√≥rico de compras: {customer_context.get('has_purchase_history', False)}

CONTEXTO SICC:
- Mem√≥rias relevantes: {sicc_context.get('memories_found', 0)}
- Padr√µes aplic√°veis: {len(sicc_patterns)}
"""
    
    # Formatar mem√≥rias relevantes do SICC
    memories_text = ""
    if sicc_context.get('memories'):
        memories_list = sicc_context['memories'][:3]  # Top 3 mem√≥rias
        if memories_list:
            memories_text = "\n\nMEM√ìRIAS RELEVANTES (conversas anteriores):\n"
            for i, mem in enumerate(memories_list, 1):
                content = mem.get('content', '')[:150]
                memories_text += f"{i}. {content}...\n"
            memories_text += "\nUSE essas mem√≥rias para entender o hist√≥rico do cliente e personalizar o suporte!\n"
    
    # Formatar padr√µes aplic√°veis
    patterns_text = ""
    if sicc_patterns:
        patterns_text = f"\n\nPADR√ïES DETECTADOS: {len(sicc_patterns)} padr√µes aplic√°veis"
        for pattern in sicc_patterns[:2]:  # Top 2 padr√µes
            pattern_desc = pattern.get('description', '')
            if pattern_desc:
                patterns_text += f"\n- {pattern_desc}"
    
    # Prompt de suporte com contexto SICC
    system_prompt = f"""Voc√™ √© BIA, assistente de suporte da Slim Quality.

{personalization}

Cliente: {nome if nome else 'Cliente'}
{memories_text}
{patterns_text}

INFORMA√á√ïES DA EMPRESA:

**Garantia:**
- 10 anos de garantia contra defeitos de fabrica√ß√£o
- Cobre: afundamento, deforma√ß√£o, quebra de molas
- N√£o cobre: desgaste natural, manchas, rasgos

**Frete:**
- GR√ÅTIS para todo o Brasil
- Prazo: 7-15 dias √∫teis (varia por regi√£o)
- Entrega rastre√°vel

**Pol√≠tica de Troca:**
- 100 noites de teste em casa
- Se n√£o gostar, devolvemos 100% do valor
- Coleta gratuita
- Sem perguntas, sem burocracia

**Pagamento:**
- At√© 12x sem juros no cart√£o
- PIX (5% de desconto)
- Boleto banc√°rio
- Aceita todos os cart√µes

**Contato:**
- WhatsApp: (11) 99999-9999
- Email: contato@slimquality.com.br
- Hor√°rio: Seg-Sex 9h-18h, S√°b 9h-13h

SUA MISS√ÉO:
1. Responder d√∫vidas com precis√£o
2. Ser emp√°tica e resolver problemas
3. Se n√£o souber, seja honesta e ofere√ßa transferir para humano
4. Tranquilizar o cliente sobre pol√≠ticas generosas
5. Se cliente √© retornando, reconhe√ßa isso e use hist√≥rico
6. USE as mem√≥rias relevantes para entender contexto e problemas anteriores

QUANDO TRANSFERIR PARA HUMANO:
- Reclama√ß√µes graves ou complexas
- Problemas que voc√™ n√£o consegue resolver
- Cliente solicita explicitamente
- Quest√µes financeiras espec√≠ficas (reembolso, estorno)

ESTILO:
- Profissional mas amig√°vel
- Use emojis moderadamente
- Seja clara e objetiva
- Demonstre empatia
- Se cliente tem hist√≥rico, mostre que voc√™ lembra dele
"""
    
    try:
        # Invocar Claude com hist√≥rico completo
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            *state["messages"]
        ])
        
        logger.info("support_node: Resposta de suporte gerada")
        
        # Detectar se precisa transferir para humano
        needs_transfer = detect_human_transfer(response.content)
        
        if needs_transfer:
            logger.warning("support_node: Transfer√™ncia para humano detectada")
            # TODO: Integrar com MCP tool para notificar humano
            # await mcp_gateway.execute_tool("notify_human", {
            #     "lead_id": state["lead_id"],
            #     "reason": "Solicita√ß√£o de suporte complexo"
            # })
        
        # Atualizar estado
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content=response.content)]
        }
        
    except Exception as e:
        logger.error(f"support_node: Erro ao gerar resposta: {e}")
        # Resposta de fallback
        fallback_message = "Desculpe, tive um problema. Vou transferir voc√™ para um atendente humano. Um momento! üôè"
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content=fallback_message)]
        }
